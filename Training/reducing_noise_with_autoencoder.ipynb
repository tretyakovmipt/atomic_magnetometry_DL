{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, save_model\n",
    "from tensorflow.keras.layers import Conv1D, Conv1DTranspose, Dense\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "X_train = np.load('..\\data\\X_train_c.npy')  # population in F=1\n",
    "Y_train = np.load('..\\data\\Y_train_c.npy')  #normalized to w_L\n",
    "\n",
    "X_test = np.load('..\\data\\X_val_C.npy')  # use validation set for testing\n",
    "Y_test = np.load('..\\data\\Y_val_C.npy')  # use validation set for testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Normalize inputs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "Level = np.min(X_train)\n",
    "Height = np.max(X_train) - np.min(X_train)\n",
    "\n",
    "X_train = (X_train - Level) / Height\n",
    "X_test = (X_test - Level) / Height"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reshape data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train = X_train[:, :, np.newaxis]\n",
    "X_test = X_test[:, :, np.newaxis]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Callbacks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=500, monitor='val_loss', restore_best_weights=True) # Stop if the validation loss is not improving\n",
    "learning_rate_cb = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=100) # Decrease the learning rate if the validation loss is not improving\n",
    "cb_list = [early_stopping_cb, learning_rate_cb]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "max_norm_value = 2.0\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(64, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform', input_shape=X_train[0].shape))\n",
    "model.add(Conv1D(32, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Conv1D(16, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Conv1DTranspose(16, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Conv1DTranspose(32, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Conv1DTranspose(64, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Conv1D(320, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', padding='same'))\n",
    "model.add(Conv1D(1, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='tanh', padding='same'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"mae\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I do the training 10 times, each time generating new random noisein the input."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "8/8 [==============================] - 1s 59ms/step - loss: 0.0580 - mae: 0.0154 - val_loss: 0.0497 - val_mae: 0.0076 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0499 - mae: 0.0070 - val_loss: 0.0500 - val_mae: 0.0100 - lr: 0.0010\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0472 - mae: 0.0053 - val_loss: 0.0466 - val_mae: 0.0038 - lr: 0.0010\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0462 - mae: 0.0034 - val_loss: 0.0457 - val_mae: 0.0035 - lr: 0.0010\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0457 - mae: 0.0029 - val_loss: 0.0456 - val_mae: 0.0027 - lr: 0.0010\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0023 - val_loss: 0.0454 - val_mae: 0.0021 - lr: 0.0010\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0021 - val_loss: 0.0453 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0018 - val_loss: 0.0453 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0453 - mae: 0.0018 - val_loss: 0.0453 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0452 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0017 - val_loss: 0.0452 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0453 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0456 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0456 - mae: 0.0019 - val_loss: 0.0457 - val_mae: 0.0028 - lr: 0.0010\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0457 - mae: 0.0022 - val_loss: 0.0454 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0018 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0455 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0457 - mae: 0.0021 - val_loss: 0.0456 - val_mae: 0.0026 - lr: 0.0010\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0456 - mae: 0.0020 - val_loss: 0.0455 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0019 - val_loss: 0.0454 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0016 - val_loss: 0.0454 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0016 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0455 - val_mae: 0.0021 - lr: 0.0010\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0018 - val_loss: 0.0454 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0456 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0455 - mae: 0.0018 - val_loss: 0.0457 - val_mae: 0.0025 - lr: 0.0010\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0459 - mae: 0.0025 - val_loss: 0.0455 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0457 - mae: 0.0021 - val_loss: 0.0456 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0021 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0018 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0018 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0016 - val_loss: 0.0453 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0454 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0454 - mae: 0.0016 - val_loss: 0.0454 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 59/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0456 - val_mae: 0.0023 - lr: 0.0010\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0453 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0455 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0455 - mae: 0.0017 - val_loss: 0.0456 - val_mae: 0.0026 - lr: 0.0010\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0456 - mae: 0.0020 - val_loss: 0.0456 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0455 - mae: 0.0018 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0457 - mae: 0.0022 - val_loss: 0.0455 - val_mae: 0.0021 - lr: 0.0010\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0456 - mae: 0.0020 - val_loss: 0.0458 - val_mae: 0.0024 - lr: 0.0010\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0457 - mae: 0.0023 - val_loss: 0.0456 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0455 - mae: 0.0019 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0017 - val_loss: 0.0454 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0456 - mae: 0.0019 - val_loss: 0.0455 - val_mae: 0.0018 - lr: 0.0010\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0018 - val_loss: 0.0456 - val_mae: 0.0029 - lr: 0.0010\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0455 - mae: 0.0020 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0454 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0454 - val_mae: 0.0019 - lr: 0.0010\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0020 - lr: 0.0010\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0456 - mae: 0.0020 - val_loss: 0.0453 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0456 - mae: 0.0019 - val_loss: 0.0459 - val_mae: 0.0021 - lr: 0.0010\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0457 - mae: 0.0023 - val_loss: 0.0456 - val_mae: 0.0022 - lr: 0.0010\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0019 - val_loss: 0.0456 - val_mae: 0.0022 - lr: 0.0010\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0018 - val_loss: 0.0454 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0452 - val_mae: 0.0016 - lr: 0.0010\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0014 - val_loss: 0.0452 - val_mae: 0.0015 - lr: 0.0010\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0455 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0462 - mae: 0.0026 - val_loss: 0.0465 - val_mae: 0.0046 - lr: 0.0010\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0461 - mae: 0.0034 - val_loss: 0.0461 - val_mae: 0.0028 - lr: 0.0010\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.0459 - mae: 0.0026 - val_loss: 0.0454 - val_mae: 0.0021 - lr: 0.0010\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0455 - mae: 0.0020 - val_loss: 0.0454 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0454 - mae: 0.0017 - val_loss: 0.0453 - val_mae: 0.0017 - lr: 0.0010\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.0453 - mae: 0.0016 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.0453 - mae: 0.0015 - val_loss: 0.0452 - val_mae: 0.0014 - lr: 0.0010\n",
      "Epoch 111/2000\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.0457 - mae: 0.0015"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_19112\\1759099223.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mX_train_N\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX_train\u001B[0m \u001B[1;33m+\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnormal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnoise_level\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompile\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'adam'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'binary_crossentropy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"mae\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m     \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_N\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2000\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test_N\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1443\u001B[0m                 \u001B[0mmodel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1444\u001B[0m                 steps_per_execution=self._steps_per_execution)\n\u001B[1;32m-> 1445\u001B[1;33m           val_logs = self.evaluate(\n\u001B[0m\u001B[0;32m   1446\u001B[0m               \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_x\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1447\u001B[0m               \u001B[0my\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_y\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mevaluate\u001B[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[0;32m   1748\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_test_counter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massign\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1749\u001B[0m       \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_test_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1750\u001B[1;33m       \u001B[1;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miterator\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0menumerate_epochs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Single epoch.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1751\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_metrics\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1752\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcatch_stop_iteration\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36menumerate_epochs\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1191\u001B[0m     \u001B[1;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1192\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_truncate_execution_to_epoch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1193\u001B[1;33m       \u001B[0mdata_iterator\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0miter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1194\u001B[0m       \u001B[1;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_initial_epoch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_epochs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1195\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# Set by `catch_stop_iteration`.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001B[0m in \u001B[0;36m__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    492\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minside_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    493\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcolocate_with\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_variant_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 494\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0miterator_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOwnedIterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    495\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    496\u001B[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, dataset, components, element_spec)\u001B[0m\n\u001B[0;32m    694\u001B[0m             \u001B[1;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    695\u001B[0m             \"not be specified.\")\n\u001B[1;32m--> 696\u001B[1;33m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_create_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    697\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    698\u001B[0m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_get_next_call_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py\u001B[0m in \u001B[0;36m_create_iterator\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m    719\u001B[0m               \u001B[0moutput_types\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_flat_output_types\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    720\u001B[0m               output_shapes=self._flat_output_shapes))\n\u001B[1;32m--> 721\u001B[1;33m       \u001B[0mgen_dataset_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmake_iterator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mds_variant\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterator_resource\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    722\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    723\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m__iter__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001B[0m in \u001B[0;36mmake_iterator\u001B[1;34m(dataset, iterator, name)\u001B[0m\n\u001B[0;32m   3406\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mtld\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_eager\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3407\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 3408\u001B[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001B[0m\u001B[0;32m   3409\u001B[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001B[0;32m   3410\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "noise_level = 0.01\n",
    "X_test_N = X_test + np.random.normal(0, noise_level, X_test.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    X_train_N = X_train + np.random.normal(0, noise_level, X_train.shape)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"mae\"])\n",
    "    history = model.fit(X_train_N, X_train, epochs=2000, validation_data=(X_test_N, X_test), batch_size=32, callbacks=cb_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "h = history.history\n",
    "\n",
    "training_data = pd.DataFrame({\"training loss\": h[\"loss\"], \"test_loss\": h[\"val_loss\"]})\n",
    "training_data.index.name = 'CNN Epoch'\n",
    "\n",
    "fig = training_data.plot()\n",
    "fig.set_xlabel(r'epoch_count', fontsize=12)\n",
    "fig.set_ylabel(r'Loss', fontsize=12)\n",
    "\n",
    "test = model.predict(X_test_N)  #pred\n",
    "\n",
    "index = 200\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(X_test_N[index])), X_test_N[index], label='noisy input')\n",
    "ax.plot(range(len(X_test[index])), X_test[index], label='original input', ls='--')\n",
    "ax.legend(loc=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(X_test_N[index])), X_test_N[index], label='noisy input')\n",
    "ax.plot(range(len(test[index])), test[index], label='output')\n",
    "ax.plot(range(len(test[index])), test[index], label='output', ls='--')\n",
    "ax.legend(loc=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(X_test[index])), X_test[index], label='original input')\n",
    "ax.plot(range(len(test[index])), test[index], label='output', ls='--')\n",
    "ax.legend(loc=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(X_test_N[index])), X_test_N[index] - X_test[index], label='diference')\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylim(-0.5, 0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}